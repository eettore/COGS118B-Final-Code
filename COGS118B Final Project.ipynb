{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Downloads/features_30_sec.csv', sep=',')\n",
    "df = df.drop(['filename'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>3805.839606</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>3550.522098</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>3042.260232</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>2184.745799</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>3579.757627</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.352063</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>2008.149458</td>\n",
       "      <td>282174.689224</td>\n",
       "      <td>2106.541053</td>\n",
       "      <td>88609.749506</td>\n",
       "      <td>4253.557033</td>\n",
       "      <td>...</td>\n",
       "      <td>45.050526</td>\n",
       "      <td>-13.289984</td>\n",
       "      <td>41.754955</td>\n",
       "      <td>2.484145</td>\n",
       "      <td>36.778877</td>\n",
       "      <td>-6.713265</td>\n",
       "      <td>54.866825</td>\n",
       "      <td>-1.193787</td>\n",
       "      <td>49.950665</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.398687</td>\n",
       "      <td>0.075086</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>2006.843354</td>\n",
       "      <td>182114.709510</td>\n",
       "      <td>2068.942009</td>\n",
       "      <td>82426.016726</td>\n",
       "      <td>4149.338328</td>\n",
       "      <td>...</td>\n",
       "      <td>33.851742</td>\n",
       "      <td>-10.848309</td>\n",
       "      <td>39.395096</td>\n",
       "      <td>1.881229</td>\n",
       "      <td>32.010040</td>\n",
       "      <td>-7.461491</td>\n",
       "      <td>39.196327</td>\n",
       "      <td>-2.795338</td>\n",
       "      <td>31.773624</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.432142</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>2077.526598</td>\n",
       "      <td>231657.968040</td>\n",
       "      <td>1927.293153</td>\n",
       "      <td>74717.124394</td>\n",
       "      <td>4031.405321</td>\n",
       "      <td>...</td>\n",
       "      <td>33.597008</td>\n",
       "      <td>-12.845291</td>\n",
       "      <td>36.367264</td>\n",
       "      <td>3.440978</td>\n",
       "      <td>36.001110</td>\n",
       "      <td>-12.588070</td>\n",
       "      <td>42.502201</td>\n",
       "      <td>-2.106337</td>\n",
       "      <td>29.865515</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.362485</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>1398.699344</td>\n",
       "      <td>240318.731073</td>\n",
       "      <td>1818.450280</td>\n",
       "      <td>109090.207161</td>\n",
       "      <td>3015.631004</td>\n",
       "      <td>...</td>\n",
       "      <td>46.324894</td>\n",
       "      <td>-4.416050</td>\n",
       "      <td>43.583942</td>\n",
       "      <td>1.556207</td>\n",
       "      <td>34.331261</td>\n",
       "      <td>-5.041897</td>\n",
       "      <td>47.227180</td>\n",
       "      <td>-3.590644</td>\n",
       "      <td>41.299088</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>661794</td>\n",
       "      <td>0.358401</td>\n",
       "      <td>0.085884</td>\n",
       "      <td>0.054454</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1609.795082</td>\n",
       "      <td>422203.216152</td>\n",
       "      <td>1797.213044</td>\n",
       "      <td>120115.632927</td>\n",
       "      <td>3246.908930</td>\n",
       "      <td>...</td>\n",
       "      <td>59.167755</td>\n",
       "      <td>-7.069775</td>\n",
       "      <td>73.760391</td>\n",
       "      <td>0.028346</td>\n",
       "      <td>76.504326</td>\n",
       "      <td>-2.025783</td>\n",
       "      <td>72.189316</td>\n",
       "      <td>1.155239</td>\n",
       "      <td>49.662510</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0    661794          0.350088         0.088757  0.130228  0.002827   \n",
       "1    661794          0.340914         0.094980  0.095948  0.002373   \n",
       "2    661794          0.363637         0.085275  0.175570  0.002746   \n",
       "3    661794          0.404785         0.093999  0.141093  0.006346   \n",
       "4    661794          0.308526         0.087841  0.091529  0.002303   \n",
       "..      ...               ...              ...       ...       ...   \n",
       "995  661794          0.352063         0.080487  0.079486  0.000345   \n",
       "996  661794          0.398687         0.075086  0.076458  0.000588   \n",
       "997  661794          0.432142         0.075268  0.081651  0.000322   \n",
       "998  661794          0.362485         0.091506  0.083860  0.001211   \n",
       "999  661794          0.358401         0.085884  0.054454  0.000336   \n",
       "\n",
       "     spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0               1784.165850          129774.064525              2002.449060   \n",
       "1               1530.176679          375850.073649              2039.036516   \n",
       "2               1552.811865          156467.643368              1747.702312   \n",
       "3               1070.106615          184355.942417              1596.412872   \n",
       "4               1835.004266          343399.939274              1748.172116   \n",
       "..                      ...                    ...                      ...   \n",
       "995             2008.149458          282174.689224              2106.541053   \n",
       "996             2006.843354          182114.709510              2068.942009   \n",
       "997             2077.526598          231657.968040              1927.293153   \n",
       "998             1398.699344          240318.731073              1818.450280   \n",
       "999             1609.795082          422203.216152              1797.213044   \n",
       "\n",
       "     spectral_bandwidth_var  rolloff_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0              85882.761315   3805.839606  ...   52.420910    -1.690215   \n",
       "1             213843.755497   3550.522098  ...   55.356403    -0.731125   \n",
       "2              76254.192257   3042.260232  ...   40.598766    -7.729093   \n",
       "3             166441.494769   2184.745799  ...   44.427753    -3.319597   \n",
       "4              88445.209036   3579.757627  ...   86.099236    -5.454034   \n",
       "..                      ...           ...  ...         ...          ...   \n",
       "995            88609.749506   4253.557033  ...   45.050526   -13.289984   \n",
       "996            82426.016726   4149.338328  ...   33.851742   -10.848309   \n",
       "997            74717.124394   4031.405321  ...   33.597008   -12.845291   \n",
       "998           109090.207161   3015.631004  ...   46.324894    -4.416050   \n",
       "999           120115.632927   3246.908930  ...   59.167755    -7.069775   \n",
       "\n",
       "     mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0     36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1     60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2     47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3     50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4     75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "..          ...          ...         ...          ...         ...   \n",
       "995   41.754955     2.484145   36.778877    -6.713265   54.866825   \n",
       "996   39.395096     1.881229   32.010040    -7.461491   39.196327   \n",
       "997   36.367264     3.440978   36.001110   -12.588070   42.502201   \n",
       "998   43.583942     1.556207   34.331261    -5.041897   47.227180   \n",
       "999   73.760391     0.028346   76.504326    -2.025783   72.189316   \n",
       "\n",
       "     mfcc20_mean  mfcc20_var  label  \n",
       "0       1.221291   46.936035  blues  \n",
       "1       0.531217   45.786282  blues  \n",
       "2      -2.231258   30.573025  blues  \n",
       "3      -3.407448   31.949339  blues  \n",
       "4     -11.703234   55.195160  blues  \n",
       "..           ...         ...    ...  \n",
       "995    -1.193787   49.950665   rock  \n",
       "996    -2.795338   31.773624   rock  \n",
       "997    -2.106337   29.865515   rock  \n",
       "998    -3.590644   41.299088   rock  \n",
       "999     1.155239   49.662510   rock  \n",
       "\n",
       "[1000 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = df.loc[:,'label']\n",
    "X_p = df.drop(['label'], axis=1)\n",
    "\n",
    "stdscale = StandardScaler(with_mean=False, with_std=False)\n",
    "X_p = stdscale.fit_transform(X_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 2s, sys: 27.1 s, total: 3min 29s\n",
      "Wall time: 3min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "# In this case, 12 possible values of C\n",
    "param_grid = {\n",
    "    \"C\": [10**(-6), 10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1),\n",
    "        0, 10**(0), 10**(1), 10**(2), 10**(3), 10**(4)]}\n",
    "\n",
    "\n",
    "# Array to store scores\n",
    "lrscores = np.zeros(3)\n",
    "best_lrmodel = []\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(3):\n",
    "\n",
    "     # Create test/train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=3,\n",
    "                                                    stratify=y_p)\n",
    "    # Create inner cv\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(lr, param_grid, cv=inner_cv, n_jobs = -1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    lrscores[i] = clf.best_score_\n",
    "    best_lrmodel.append(clf.best_estimator_.fit(X_train, y_train))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46375, 0.4775 , 0.49   ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1000, max_iter=10000),\n",
       " LogisticRegression(C=0.0001, max_iter=10000),\n",
       " LogisticRegression(C=1000, max_iter=10000)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lrmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.60153904e+01, 1.62372821e+01, 1.48585456e+01, 1.41863004e+01,\n",
       "        1.48799084e+01, 1.43020267e+01, 6.41303062e-03, 1.44630464e+01,\n",
       "        1.42250195e+01, 1.37319678e+01, 1.17265543e+01, 8.29174910e+00]),\n",
       " 'std_fit_time': array([1.60224297e-01, 7.66420975e-01, 1.06834898e+00, 1.89545598e-01,\n",
       "        7.64862303e-01, 1.66807190e-01, 1.09606433e-04, 3.78360140e-01,\n",
       "        9.82506717e-01, 1.80831499e-01, 2.42761670e+00, 1.29788366e-01]),\n",
       " 'mean_score_time': array([0.00105906, 0.00101547, 0.00123577, 0.00100183, 0.00099168,\n",
       "        0.0009831 , 0.        , 0.00127721, 0.0009831 , 0.00102482,\n",
       "        0.00061622, 0.00059443]),\n",
       " 'std_score_time': array([8.84804722e-05, 3.85408334e-05, 4.30177035e-04, 3.06079688e-05,\n",
       "        3.62203572e-05, 2.39449181e-05, 0.00000000e+00, 6.00646786e-04,\n",
       "        1.25668079e-05, 1.31756811e-04, 1.72463807e-04, 1.78570162e-04]),\n",
       " 'param_C': masked_array(data=[1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 0, 1, 10, 100,\n",
       "                    1000, 10000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1e-06},\n",
       "  {'C': 1e-05},\n",
       "  {'C': 0.0001},\n",
       "  {'C': 0.001},\n",
       "  {'C': 0.01},\n",
       "  {'C': 0.1},\n",
       "  {'C': 0},\n",
       "  {'C': 1},\n",
       "  {'C': 10},\n",
       "  {'C': 100},\n",
       "  {'C': 1000},\n",
       "  {'C': 10000}],\n",
       " 'split0_test_score': array([0.53125, 0.50625, 0.5375 , 0.53125, 0.50625, 0.53125,     nan,\n",
       "        0.5    , 0.53125, 0.5625 , 0.5625 , 0.525  ]),\n",
       " 'split1_test_score': array([0.51875, 0.5125 , 0.49375, 0.525  , 0.49375, 0.50625,     nan,\n",
       "        0.50625, 0.4875 , 0.48125, 0.54375, 0.5125 ]),\n",
       " 'split2_test_score': array([0.4    , 0.39375, 0.3875 , 0.4    , 0.3875 , 0.3875 ,     nan,\n",
       "        0.4125 , 0.4    , 0.40625, 0.4125 , 0.3875 ]),\n",
       " 'split3_test_score': array([0.4375 , 0.4625 , 0.46875, 0.45   , 0.43125, 0.475  ,     nan,\n",
       "        0.4625 , 0.44375, 0.4625 , 0.4875 , 0.49375]),\n",
       " 'split4_test_score': array([0.41875, 0.41875, 0.40625, 0.40625, 0.4125 , 0.4    ,     nan,\n",
       "        0.44375, 0.4375 , 0.45   , 0.44375, 0.41875]),\n",
       " 'mean_test_score': array([0.46125, 0.45875, 0.45875, 0.4625 , 0.44625, 0.46   ,     nan,\n",
       "        0.465  , 0.46   , 0.4725 , 0.49   , 0.4675 ]),\n",
       " 'std_test_score': array([0.05353153, 0.04687083, 0.0554245 , 0.0563194 , 0.0461993 ,\n",
       "        0.05709094,        nan, 0.03504461, 0.04517328, 0.05132616,\n",
       "        0.05709094, 0.05440014]),\n",
       " 'rank_test_score': array([ 6,  9,  9,  5, 11,  8, 12,  4,  7,  2,  1,  3], dtype=int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Train and Test with Optimal Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, max_iter=10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.80,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "stdscale.fit(X_train)\n",
    "\n",
    "X_train = stdscale.transform(X_train)\n",
    "X_test = stdscale.transform(X_test)\n",
    "\n",
    "#optimized parameters\n",
    "classifier = LogisticRegression(C = 1000, max_iter = 10000)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.465])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test:\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "matches = (pred==y_test).sum()\n",
    "\n",
    "accuracy = matches / pred.shape\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN: Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.89 s, sys: 160 ms, total: 2.05 s\n",
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "my_list = list(range(1, 501, 50))\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "# In this case, 10 values of K, 2 values for weights,\n",
    "# three potential algorithms and 3 leaf sizes.\n",
    "param_grid = {\n",
    "    \"n_neighbors\": my_list,\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    \"algorithm\": ['auto', 'ball_tree', 'kd_tree'],\n",
    "    \"leaf_size\": [20, 30, 40]}\n",
    "\n",
    "# Array to store scores\n",
    "knnscores = np.zeros(3)\n",
    "best_knnmodel = []\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(3): #NUM_TRIALS\n",
    "\n",
    "     # Create test/train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y_p)\n",
    "    # Create inner cv\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), param_grid, cv=inner_cv, n_jobs = -1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    knnscores[i] = clf.best_score_\n",
    "    best_knnmodel.append(clf.best_estimator_.fit(X_train, y_train))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28   , 0.30125, 0.3075 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KNeighborsClassifier(leaf_size=20, n_neighbors=151, weights='distance'),\n",
       " KNeighborsClassifier(leaf_size=20, n_neighbors=351, weights='distance'),\n",
       " KNeighborsClassifier(leaf_size=20, n_neighbors=51, weights='distance')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knnmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00202713, 0.00189376, 0.0021625 , 0.00225482, 0.0021801 ,\n",
       "        0.00254898, 0.00266528, 0.00281243, 0.00242214, 0.00236964,\n",
       "        0.00236969, 0.00230818, 0.00258579, 0.00200434, 0.00128107,\n",
       "        0.00172663, 0.00172658, 0.00176268, 0.00160508, 0.0017715 ,\n",
       "        0.0028729 , 0.00321693, 0.00298734, 0.00291281, 0.00284133,\n",
       "        0.00303226, 0.00263834, 0.00266819, 0.00279303, 0.00258923,\n",
       "        0.00258083, 0.00260386, 0.00290847, 0.0031559 , 0.00182905,\n",
       "        0.00179844, 0.00184455, 0.00182862, 0.00209632, 0.00202565,\n",
       "        0.00282288, 0.00284381, 0.00359607, 0.00291271, 0.00289159,\n",
       "        0.00290523, 0.00290322, 0.00288081, 0.00280437, 0.00286174,\n",
       "        0.00294876, 0.00282235, 0.00274673, 0.0033669 , 0.00171022,\n",
       "        0.00179243, 0.00185785, 0.00158057, 0.00162334, 0.00172091,\n",
       "        0.0027669 , 0.00330176, 0.00372629, 0.00283437, 0.00287838,\n",
       "        0.00290642, 0.00289669, 0.00278034, 0.00344639, 0.00282035,\n",
       "        0.00277276, 0.00298743, 0.00277748, 0.00237579, 0.00272331,\n",
       "        0.00265007, 0.00237379, 0.00263581, 0.00344958, 0.00239844,\n",
       "        0.00245028, 0.00287957, 0.00275512, 0.00246725, 0.00346293,\n",
       "        0.00282478, 0.00268798, 0.00251207, 0.0028326 , 0.00249019,\n",
       "        0.00242715, 0.0027154 , 0.0024353 , 0.00236168, 0.00259132,\n",
       "        0.00239615, 0.00250921, 0.00266418, 0.00244722, 0.00252943,\n",
       "        0.00233502, 0.00226722, 0.00238152, 0.00233846, 0.00217977,\n",
       "        0.00241952, 0.0023066 , 0.00231919, 0.00227499, 0.00250134,\n",
       "        0.00234981, 0.00257511, 0.002529  , 0.00216522, 0.00241671,\n",
       "        0.0023098 , 0.0023077 , 0.00275917, 0.00217824, 0.00231233,\n",
       "        0.00277524, 0.00257454, 0.00292964, 0.00287013, 0.00253248,\n",
       "        0.00248408, 0.00270033, 0.00245161, 0.00252795, 0.0028636 ,\n",
       "        0.00258222, 0.00256782, 0.00273151, 0.00250697, 0.00236521,\n",
       "        0.00326085, 0.00235896, 0.00260153, 0.00301275, 0.00251379,\n",
       "        0.00245066, 0.00355377, 0.00258522, 0.00234656, 0.00246768,\n",
       "        0.00250382, 0.00279732, 0.00271654, 0.00290065, 0.00244498,\n",
       "        0.00245628, 0.00248685, 0.00287423, 0.00294318, 0.00302987,\n",
       "        0.00292411, 0.00299387, 0.00275221, 0.00260763, 0.00288687,\n",
       "        0.00273938, 0.0025538 , 0.00214572, 0.00210056, 0.00261474,\n",
       "        0.0025034 , 0.00284228, 0.00269718, 0.00283804, 0.00264263,\n",
       "        0.00264726, 0.00256882, 0.00259347, 0.00245752, 0.00283461,\n",
       "        0.00327439, 0.00312152, 0.00313234, 0.00286918, 0.00291457]),\n",
       " 'std_fit_time': array([2.10719223e-04, 6.38377933e-05, 2.34600703e-04, 4.40637078e-04,\n",
       "        2.90057931e-04, 2.76407303e-04, 2.33366902e-04, 1.42965005e-04,\n",
       "        3.42993757e-04, 3.68928019e-04, 9.15491829e-05, 1.05179123e-04,\n",
       "        4.08720257e-04, 3.10648865e-04, 1.81436407e-04, 4.67767604e-04,\n",
       "        2.80990205e-04, 3.35234747e-04, 2.88445943e-04, 3.22776648e-04,\n",
       "        3.01768926e-04, 3.76915340e-04, 1.22173311e-04, 1.56516769e-04,\n",
       "        7.75815082e-05, 5.31233349e-04, 1.47576979e-04, 3.29457259e-04,\n",
       "        5.12610466e-04, 1.82739777e-04, 3.05004385e-04, 3.56313694e-04,\n",
       "        7.31136267e-04, 9.49728652e-04, 1.84400802e-04, 3.20790525e-04,\n",
       "        2.00059188e-05, 1.44124092e-04, 4.46124437e-04, 1.47788014e-04,\n",
       "        5.02097188e-04, 1.69501183e-04, 1.20320274e-03, 1.17205992e-04,\n",
       "        7.67857969e-05, 2.05655372e-04, 1.22228349e-04, 8.37208462e-05,\n",
       "        1.28061861e-04, 8.35592326e-05, 2.71950854e-04, 1.11794815e-04,\n",
       "        1.39162259e-04, 1.38299533e-03, 1.29701758e-04, 1.99636121e-04,\n",
       "        1.37759699e-04, 2.16993686e-04, 2.01601619e-04, 1.28960255e-04,\n",
       "        3.63272574e-04, 4.07730140e-04, 1.13722107e-03, 2.20367206e-04,\n",
       "        2.54053244e-04, 1.72266727e-04, 3.42448486e-04, 1.55985643e-04,\n",
       "        1.46796921e-03, 3.21649818e-04, 2.38314816e-04, 6.13362986e-04,\n",
       "        3.09461827e-04, 6.88918973e-05, 7.09824294e-04, 2.34665000e-04,\n",
       "        9.99740702e-05, 4.90893273e-04, 1.28685412e-03, 9.37165663e-05,\n",
       "        9.78417562e-05, 2.90017416e-04, 2.14281430e-04, 4.53282817e-05,\n",
       "        1.41591286e-03, 3.02973227e-04, 4.68868437e-04, 1.27329504e-04,\n",
       "        4.39458553e-04, 2.17949533e-05, 1.01710651e-04, 2.96766508e-04,\n",
       "        1.44246243e-04, 5.73295507e-05, 2.13219664e-04, 1.24202250e-04,\n",
       "        1.84665593e-04, 1.95763903e-04, 1.70616880e-04, 2.33236570e-04,\n",
       "        1.17895651e-04, 1.99600389e-04, 6.54581932e-05, 1.20117296e-04,\n",
       "        9.82459988e-05, 1.96527346e-04, 5.67359278e-05, 1.18357246e-04,\n",
       "        1.18694050e-04, 1.77060662e-04, 2.97231515e-04, 2.40980140e-04,\n",
       "        3.48232273e-04, 4.47776751e-05, 1.57465579e-04, 1.11531691e-04,\n",
       "        7.52464144e-05, 9.87979498e-04, 5.64540559e-05, 1.82013222e-04,\n",
       "        2.31399861e-04, 1.85919022e-04, 3.82110814e-04, 3.08061915e-04,\n",
       "        6.08975379e-05, 7.19152011e-05, 3.80781895e-04, 1.20978239e-04,\n",
       "        1.81783496e-04, 1.43065563e-04, 2.97216338e-04, 8.74195330e-05,\n",
       "        3.20480243e-04, 2.52542926e-04, 4.12866639e-05, 4.42296166e-04,\n",
       "        7.00548926e-05, 2.46052576e-04, 1.31753791e-04, 2.26380398e-04,\n",
       "        1.08945698e-04, 1.94771517e-03, 1.98702478e-04, 5.08475679e-05,\n",
       "        9.75802012e-05, 1.08044335e-04, 4.56220798e-04, 1.48176332e-04,\n",
       "        3.18478406e-04, 8.40738421e-05, 1.61776281e-04, 1.60781938e-04,\n",
       "        1.71161267e-04, 1.42661645e-04, 9.47578019e-05, 1.26006563e-04,\n",
       "        3.05095990e-04, 9.01495423e-05, 1.78551125e-04, 2.09220072e-04,\n",
       "        1.43509084e-04, 4.12687467e-04, 4.30062534e-04, 3.56917521e-04,\n",
       "        3.05541981e-04, 3.23990901e-04, 5.40179616e-04, 2.34286037e-04,\n",
       "        1.13291190e-04, 2.09723694e-04, 1.01209695e-04, 2.17037481e-04,\n",
       "        1.02690887e-04, 3.06487379e-04, 3.17256694e-04, 1.32359453e-03,\n",
       "        3.64328010e-04, 1.52071661e-04, 7.17105698e-05, 2.00753348e-04]),\n",
       " 'mean_score_time': array([0.00791245, 0.00281205, 0.01040692, 0.00651689, 0.01453953,\n",
       "        0.01101918, 0.01828299, 0.01317921, 0.02002769, 0.01469765,\n",
       "        0.02048812, 0.01694555, 0.02086139, 0.01812763, 0.0162262 ,\n",
       "        0.01682181, 0.02008696, 0.01948671, 0.02194395, 0.02083917,\n",
       "        0.01133547, 0.00524087, 0.02147455, 0.00824656, 0.01709437,\n",
       "        0.01058917, 0.01695142, 0.01254106, 0.01979055, 0.01546717,\n",
       "        0.02103238, 0.01913409, 0.02390761, 0.02444849, 0.02247896,\n",
       "        0.01801443, 0.0209435 , 0.02054257, 0.02238655, 0.02193441,\n",
       "        0.01319089, 0.00470347, 0.01635375, 0.00967569, 0.01925178,\n",
       "        0.0130651 , 0.02149801, 0.01606479, 0.0223289 , 0.01841159,\n",
       "        0.02510295, 0.02138972, 0.02556329, 0.0229845 , 0.02083459,\n",
       "        0.01630225, 0.02122664, 0.01875353, 0.02100444, 0.02117405,\n",
       "        0.01101665, 0.00456066, 0.01473098, 0.00716844, 0.01519446,\n",
       "        0.01009078, 0.01990566, 0.01245365, 0.02029901, 0.01682577,\n",
       "        0.02144051, 0.01739559, 0.02372637, 0.01749797, 0.02269793,\n",
       "        0.02460876, 0.02387729, 0.02382402, 0.03100271, 0.0251811 ,\n",
       "        0.00970855, 0.00411406, 0.01375399, 0.00641284, 0.01457348,\n",
       "        0.0095089 , 0.01577368, 0.01092229, 0.01961393, 0.01370983,\n",
       "        0.01958504, 0.01738038, 0.0194036 , 0.01847777, 0.02452884,\n",
       "        0.02092814, 0.02625852, 0.02495279, 0.02602258, 0.02712646,\n",
       "        0.01114516, 0.00529456, 0.01298418, 0.00912046, 0.01432309,\n",
       "        0.01037903, 0.01554661, 0.01204276, 0.01849027, 0.01486707,\n",
       "        0.0217823 , 0.01853895, 0.02125173, 0.01844826, 0.02605963,\n",
       "        0.02152615, 0.02592325, 0.02555785, 0.02570505, 0.03288879,\n",
       "        0.01050549, 0.00381212, 0.01218796, 0.00800672, 0.01433716,\n",
       "        0.00913172, 0.01736646, 0.0125824 , 0.01929865, 0.01674123,\n",
       "        0.02121696, 0.01783867, 0.02765574, 0.02011871, 0.02707467,\n",
       "        0.02648811, 0.02665462, 0.02690945, 0.03256431, 0.02803264,\n",
       "        0.00952463, 0.00397782, 0.01274467, 0.00691862, 0.0141645 ,\n",
       "        0.01085176, 0.01709619, 0.01304617, 0.02251372, 0.01451912,\n",
       "        0.02322755, 0.02033348, 0.02712383, 0.02504635, 0.03374281,\n",
       "        0.02770391, 0.02997727, 0.02966857, 0.03414993, 0.03329797,\n",
       "        0.0118259 , 0.00414987, 0.0126955 , 0.00726647, 0.0162744 ,\n",
       "        0.01194205, 0.0206934 , 0.01491361, 0.0233089 , 0.01866355,\n",
       "        0.02352281, 0.02056246, 0.02537789, 0.0233366 , 0.02833481,\n",
       "        0.02924786, 0.03408556, 0.03311234, 0.03306999, 0.02679443]),\n",
       " 'std_score_time': array([0.00037903, 0.0002423 , 0.00074937, 0.00083325, 0.00151288,\n",
       "        0.00066075, 0.00100077, 0.00107937, 0.00136597, 0.00066705,\n",
       "        0.00120498, 0.00082874, 0.00115066, 0.00202838, 0.00230009,\n",
       "        0.00130603, 0.00125609, 0.00051012, 0.0009507 , 0.00126648,\n",
       "        0.00121756, 0.00067303, 0.00805776, 0.00032669, 0.0014332 ,\n",
       "        0.00101001, 0.00120941, 0.0014125 , 0.00158797, 0.00117715,\n",
       "        0.00079159, 0.00205336, 0.00238208, 0.00486535, 0.00243551,\n",
       "        0.00290245, 0.00115151, 0.00181611, 0.00248154, 0.00142705,\n",
       "        0.00326353, 0.0003659 , 0.00093085, 0.00176504, 0.00231324,\n",
       "        0.00245835, 0.00235852, 0.00451683, 0.00217211, 0.00107512,\n",
       "        0.00152136, 0.00343663, 0.00120587, 0.00117738, 0.00259522,\n",
       "        0.00195403, 0.00104358, 0.00161319, 0.00115423, 0.0018736 ,\n",
       "        0.00105211, 0.00034742, 0.00067488, 0.0005059 , 0.0016536 ,\n",
       "        0.00096875, 0.00419308, 0.00097745, 0.00196376, 0.0021513 ,\n",
       "        0.00175019, 0.00248522, 0.00231128, 0.0005356 , 0.00069802,\n",
       "        0.00377555, 0.00083979, 0.00158225, 0.0031781 , 0.00125309,\n",
       "        0.0014264 , 0.00046824, 0.00124297, 0.00022814, 0.00207238,\n",
       "        0.00104986, 0.00046463, 0.00036081, 0.00282264, 0.00029803,\n",
       "        0.00181717, 0.00238533, 0.00030713, 0.00265814, 0.00277499,\n",
       "        0.00095029, 0.00281063, 0.00158361, 0.00167953, 0.00206135,\n",
       "        0.00068379, 0.00056038, 0.00085877, 0.00275943, 0.00117012,\n",
       "        0.00094739, 0.00068073, 0.00094761, 0.00173645, 0.00073185,\n",
       "        0.00208908, 0.00295175, 0.00066088, 0.00060144, 0.00369573,\n",
       "        0.00095846, 0.00265624, 0.00239368, 0.00189691, 0.00391887,\n",
       "        0.00078197, 0.00054596, 0.00048428, 0.00072684, 0.0005871 ,\n",
       "        0.00026104, 0.00156309, 0.000833  , 0.00115557, 0.00199538,\n",
       "        0.00157145, 0.00084451, 0.00296874, 0.00108847, 0.00314148,\n",
       "        0.00182339, 0.00243264, 0.00194901, 0.00262671, 0.00260892,\n",
       "        0.00038859, 0.00056094, 0.00083044, 0.00040672, 0.00050034,\n",
       "        0.00245319, 0.00164857, 0.00236007, 0.00269821, 0.00020686,\n",
       "        0.00337898, 0.00208882, 0.00129501, 0.00132594, 0.00590882,\n",
       "        0.00074453, 0.00122643, 0.00413717, 0.00303146, 0.00141594,\n",
       "        0.00056994, 0.00054692, 0.00167228, 0.00111303, 0.0010093 ,\n",
       "        0.00032937, 0.00102369, 0.00056433, 0.00156828, 0.00061289,\n",
       "        0.00061921, 0.00104769, 0.00060279, 0.00136859, 0.00053172,\n",
       "        0.00045639, 0.00135966, 0.00033119, 0.00355522, 0.00143635]),\n",
       " 'param_algorithm': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_leaf_size': masked_array(data=[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 40, 40,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    40, 40, 40, 40, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    30, 30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "                    30, 30, 30, 30, 30, 30, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "                    40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[1, 1, 51, 51, 101, 101, 151, 151, 201, 201, 251, 251,\n",
       "                    301, 301, 351, 351, 401, 401, 451, 451, 1, 1, 51, 51,\n",
       "                    101, 101, 151, 151, 201, 201, 251, 251, 301, 301, 351,\n",
       "                    351, 401, 401, 451, 451, 1, 1, 51, 51, 101, 101, 151,\n",
       "                    151, 201, 201, 251, 251, 301, 301, 351, 351, 401, 401,\n",
       "                    451, 451, 1, 1, 51, 51, 101, 101, 151, 151, 201, 201,\n",
       "                    251, 251, 301, 301, 351, 351, 401, 401, 451, 451, 1, 1,\n",
       "                    51, 51, 101, 101, 151, 151, 201, 201, 251, 251, 301,\n",
       "                    301, 351, 351, 401, 401, 451, 451, 1, 1, 51, 51, 101,\n",
       "                    101, 151, 151, 201, 201, 251, 251, 301, 301, 351, 351,\n",
       "                    401, 401, 451, 451, 1, 1, 51, 51, 101, 101, 151, 151,\n",
       "                    201, 201, 251, 251, 301, 301, 351, 351, 401, 401, 451,\n",
       "                    451, 1, 1, 51, 51, 101, 101, 151, 151, 201, 201, 251,\n",
       "                    251, 301, 301, 351, 351, 401, 401, 451, 451, 1, 1, 51,\n",
       "                    51, 101, 101, 151, 151, 201, 201, 251, 251, 301, 301,\n",
       "                    351, 351, 401, 401, 451, 451],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 20,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 30,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 51,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 101,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 151,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 201,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 251,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 301,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 351,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 401,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'leaf_size': 40,\n",
       "   'n_neighbors': 451,\n",
       "   'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.25   , 0.25   , 0.2125 , 0.26875, 0.1875 , 0.24375, 0.19375,\n",
       "        0.25   , 0.20625, 0.24375, 0.21875, 0.2375 , 0.16875, 0.25   ,\n",
       "        0.18125, 0.24375, 0.1875 , 0.24375, 0.15   , 0.24375, 0.25   ,\n",
       "        0.25   , 0.2125 , 0.26875, 0.1875 , 0.24375, 0.19375, 0.25   ,\n",
       "        0.20625, 0.24375, 0.21875, 0.2375 , 0.16875, 0.25   , 0.18125,\n",
       "        0.24375, 0.1875 , 0.24375, 0.15   , 0.24375, 0.25   , 0.25   ,\n",
       "        0.2125 , 0.26875, 0.1875 , 0.24375, 0.19375, 0.25   , 0.20625,\n",
       "        0.24375, 0.21875, 0.2375 , 0.16875, 0.25   , 0.18125, 0.24375,\n",
       "        0.1875 , 0.24375, 0.15   , 0.24375, 0.25   , 0.25   , 0.2125 ,\n",
       "        0.26875, 0.1875 , 0.24375, 0.19375, 0.25   , 0.20625, 0.24375,\n",
       "        0.21875, 0.2375 , 0.16875, 0.25   , 0.18125, 0.24375, 0.1875 ,\n",
       "        0.24375, 0.15   , 0.24375, 0.25   , 0.25   , 0.2125 , 0.26875,\n",
       "        0.1875 , 0.24375, 0.19375, 0.25   , 0.20625, 0.24375, 0.21875,\n",
       "        0.2375 , 0.16875, 0.25   , 0.18125, 0.24375, 0.1875 , 0.24375,\n",
       "        0.15   , 0.24375, 0.25   , 0.25   , 0.2125 , 0.26875, 0.1875 ,\n",
       "        0.24375, 0.19375, 0.25   , 0.20625, 0.24375, 0.21875, 0.2375 ,\n",
       "        0.16875, 0.25   , 0.18125, 0.24375, 0.1875 , 0.24375, 0.15   ,\n",
       "        0.24375, 0.25   , 0.25   , 0.2125 , 0.26875, 0.1875 , 0.24375,\n",
       "        0.19375, 0.25   , 0.20625, 0.24375, 0.21875, 0.2375 , 0.16875,\n",
       "        0.25   , 0.18125, 0.24375, 0.1875 , 0.24375, 0.15   , 0.24375,\n",
       "        0.25   , 0.25   , 0.2125 , 0.26875, 0.1875 , 0.24375, 0.19375,\n",
       "        0.25   , 0.20625, 0.24375, 0.21875, 0.2375 , 0.16875, 0.25   ,\n",
       "        0.18125, 0.24375, 0.1875 , 0.24375, 0.15   , 0.24375, 0.25   ,\n",
       "        0.25   , 0.2125 , 0.26875, 0.1875 , 0.24375, 0.19375, 0.25   ,\n",
       "        0.20625, 0.24375, 0.21875, 0.2375 , 0.16875, 0.25   , 0.18125,\n",
       "        0.24375, 0.1875 , 0.24375, 0.15   , 0.24375]),\n",
       " 'split1_test_score': array([0.24375, 0.24375, 0.25   , 0.2875 , 0.2375 , 0.26875, 0.2375 ,\n",
       "        0.275  , 0.2375 , 0.28125, 0.2375 , 0.28125, 0.225  , 0.2875 ,\n",
       "        0.1875 , 0.29375, 0.21875, 0.2875 , 0.14375, 0.2875 , 0.24375,\n",
       "        0.24375, 0.25   , 0.2875 , 0.2375 , 0.26875, 0.2375 , 0.275  ,\n",
       "        0.2375 , 0.28125, 0.2375 , 0.28125, 0.225  , 0.2875 , 0.1875 ,\n",
       "        0.29375, 0.21875, 0.2875 , 0.14375, 0.2875 , 0.24375, 0.24375,\n",
       "        0.25   , 0.2875 , 0.2375 , 0.26875, 0.2375 , 0.275  , 0.2375 ,\n",
       "        0.28125, 0.2375 , 0.28125, 0.225  , 0.2875 , 0.1875 , 0.29375,\n",
       "        0.21875, 0.2875 , 0.14375, 0.2875 , 0.24375, 0.24375, 0.25   ,\n",
       "        0.2875 , 0.2375 , 0.26875, 0.2375 , 0.275  , 0.2375 , 0.28125,\n",
       "        0.2375 , 0.28125, 0.225  , 0.2875 , 0.1875 , 0.29375, 0.21875,\n",
       "        0.2875 , 0.14375, 0.2875 , 0.24375, 0.24375, 0.25   , 0.2875 ,\n",
       "        0.2375 , 0.26875, 0.2375 , 0.275  , 0.2375 , 0.28125, 0.2375 ,\n",
       "        0.28125, 0.225  , 0.2875 , 0.1875 , 0.29375, 0.21875, 0.2875 ,\n",
       "        0.14375, 0.2875 , 0.24375, 0.24375, 0.25   , 0.2875 , 0.2375 ,\n",
       "        0.26875, 0.2375 , 0.275  , 0.2375 , 0.28125, 0.2375 , 0.28125,\n",
       "        0.225  , 0.2875 , 0.1875 , 0.29375, 0.21875, 0.2875 , 0.14375,\n",
       "        0.2875 , 0.24375, 0.24375, 0.25   , 0.2875 , 0.2375 , 0.26875,\n",
       "        0.2375 , 0.275  , 0.2375 , 0.28125, 0.2375 , 0.28125, 0.225  ,\n",
       "        0.2875 , 0.1875 , 0.29375, 0.21875, 0.2875 , 0.14375, 0.2875 ,\n",
       "        0.24375, 0.24375, 0.25   , 0.2875 , 0.2375 , 0.26875, 0.2375 ,\n",
       "        0.275  , 0.2375 , 0.28125, 0.2375 , 0.28125, 0.225  , 0.2875 ,\n",
       "        0.1875 , 0.29375, 0.21875, 0.2875 , 0.14375, 0.2875 , 0.24375,\n",
       "        0.24375, 0.25   , 0.2875 , 0.2375 , 0.26875, 0.2375 , 0.275  ,\n",
       "        0.2375 , 0.28125, 0.2375 , 0.28125, 0.225  , 0.2875 , 0.1875 ,\n",
       "        0.29375, 0.21875, 0.2875 , 0.14375, 0.2875 ]),\n",
       " 'split2_test_score': array([0.2875 , 0.2875 , 0.29375, 0.29375, 0.2625 , 0.325  , 0.2375 ,\n",
       "        0.33125, 0.25625, 0.33125, 0.24375, 0.35   , 0.20625, 0.3375 ,\n",
       "        0.1875 , 0.34375, 0.18125, 0.3375 , 0.15   , 0.33125, 0.2875 ,\n",
       "        0.2875 , 0.29375, 0.29375, 0.2625 , 0.325  , 0.2375 , 0.33125,\n",
       "        0.25625, 0.33125, 0.24375, 0.35   , 0.20625, 0.3375 , 0.1875 ,\n",
       "        0.34375, 0.18125, 0.3375 , 0.15   , 0.33125, 0.2875 , 0.2875 ,\n",
       "        0.29375, 0.29375, 0.2625 , 0.325  , 0.2375 , 0.33125, 0.25625,\n",
       "        0.33125, 0.24375, 0.35   , 0.20625, 0.3375 , 0.1875 , 0.34375,\n",
       "        0.18125, 0.3375 , 0.15   , 0.33125, 0.2875 , 0.2875 , 0.29375,\n",
       "        0.29375, 0.2625 , 0.325  , 0.2375 , 0.33125, 0.25625, 0.33125,\n",
       "        0.24375, 0.35   , 0.20625, 0.3375 , 0.1875 , 0.34375, 0.18125,\n",
       "        0.3375 , 0.15   , 0.33125, 0.2875 , 0.2875 , 0.29375, 0.29375,\n",
       "        0.2625 , 0.325  , 0.2375 , 0.33125, 0.25625, 0.33125, 0.24375,\n",
       "        0.35   , 0.20625, 0.3375 , 0.1875 , 0.34375, 0.18125, 0.3375 ,\n",
       "        0.15   , 0.33125, 0.2875 , 0.2875 , 0.29375, 0.29375, 0.2625 ,\n",
       "        0.325  , 0.2375 , 0.33125, 0.25625, 0.33125, 0.24375, 0.35   ,\n",
       "        0.20625, 0.3375 , 0.1875 , 0.34375, 0.18125, 0.3375 , 0.15   ,\n",
       "        0.33125, 0.2875 , 0.2875 , 0.29375, 0.29375, 0.2625 , 0.325  ,\n",
       "        0.2375 , 0.33125, 0.25625, 0.33125, 0.24375, 0.35   , 0.20625,\n",
       "        0.3375 , 0.1875 , 0.34375, 0.18125, 0.3375 , 0.15   , 0.33125,\n",
       "        0.2875 , 0.2875 , 0.29375, 0.29375, 0.2625 , 0.325  , 0.2375 ,\n",
       "        0.33125, 0.25625, 0.33125, 0.24375, 0.35   , 0.20625, 0.3375 ,\n",
       "        0.1875 , 0.34375, 0.18125, 0.3375 , 0.15   , 0.33125, 0.2875 ,\n",
       "        0.2875 , 0.29375, 0.29375, 0.2625 , 0.325  , 0.2375 , 0.33125,\n",
       "        0.25625, 0.33125, 0.24375, 0.35   , 0.20625, 0.3375 , 0.1875 ,\n",
       "        0.34375, 0.18125, 0.3375 , 0.15   , 0.33125]),\n",
       " 'split3_test_score': array([0.225  , 0.225  , 0.29375, 0.325  , 0.275  , 0.3    , 0.2375 ,\n",
       "        0.2875 , 0.2375 , 0.29375, 0.23125, 0.3    , 0.1875 , 0.3    ,\n",
       "        0.1875 , 0.29375, 0.1875 , 0.3    , 0.18125, 0.30625, 0.225  ,\n",
       "        0.225  , 0.29375, 0.325  , 0.275  , 0.3    , 0.2375 , 0.2875 ,\n",
       "        0.2375 , 0.29375, 0.23125, 0.3    , 0.1875 , 0.3    , 0.1875 ,\n",
       "        0.29375, 0.1875 , 0.3    , 0.18125, 0.30625, 0.225  , 0.225  ,\n",
       "        0.29375, 0.325  , 0.275  , 0.3    , 0.2375 , 0.2875 , 0.2375 ,\n",
       "        0.29375, 0.23125, 0.3    , 0.1875 , 0.3    , 0.1875 , 0.29375,\n",
       "        0.1875 , 0.3    , 0.18125, 0.30625, 0.225  , 0.225  , 0.29375,\n",
       "        0.325  , 0.275  , 0.3    , 0.2375 , 0.2875 , 0.2375 , 0.29375,\n",
       "        0.23125, 0.3    , 0.1875 , 0.3    , 0.1875 , 0.29375, 0.1875 ,\n",
       "        0.3    , 0.18125, 0.30625, 0.225  , 0.225  , 0.29375, 0.325  ,\n",
       "        0.275  , 0.3    , 0.2375 , 0.2875 , 0.2375 , 0.29375, 0.23125,\n",
       "        0.3    , 0.1875 , 0.3    , 0.1875 , 0.29375, 0.1875 , 0.3    ,\n",
       "        0.18125, 0.30625, 0.225  , 0.225  , 0.29375, 0.325  , 0.275  ,\n",
       "        0.3    , 0.2375 , 0.2875 , 0.2375 , 0.29375, 0.23125, 0.3    ,\n",
       "        0.1875 , 0.3    , 0.1875 , 0.29375, 0.1875 , 0.3    , 0.18125,\n",
       "        0.30625, 0.225  , 0.225  , 0.29375, 0.325  , 0.275  , 0.3    ,\n",
       "        0.2375 , 0.2875 , 0.2375 , 0.29375, 0.23125, 0.3    , 0.1875 ,\n",
       "        0.3    , 0.1875 , 0.29375, 0.1875 , 0.3    , 0.18125, 0.30625,\n",
       "        0.225  , 0.225  , 0.29375, 0.325  , 0.275  , 0.3    , 0.2375 ,\n",
       "        0.2875 , 0.2375 , 0.29375, 0.23125, 0.3    , 0.1875 , 0.3    ,\n",
       "        0.1875 , 0.29375, 0.1875 , 0.3    , 0.18125, 0.30625, 0.225  ,\n",
       "        0.225  , 0.29375, 0.325  , 0.275  , 0.3    , 0.2375 , 0.2875 ,\n",
       "        0.2375 , 0.29375, 0.23125, 0.3    , 0.1875 , 0.3    , 0.1875 ,\n",
       "        0.29375, 0.1875 , 0.3    , 0.18125, 0.30625]),\n",
       " 'split4_test_score': array([0.2375 , 0.2375 , 0.3    , 0.3625 , 0.25   , 0.30625, 0.25   ,\n",
       "        0.30625, 0.21875, 0.3125 , 0.21875, 0.3125 , 0.2125 , 0.33125,\n",
       "        0.19375, 0.33125, 0.1875 , 0.3375 , 0.1375 , 0.34375, 0.2375 ,\n",
       "        0.2375 , 0.3    , 0.3625 , 0.25   , 0.30625, 0.25   , 0.30625,\n",
       "        0.21875, 0.3125 , 0.21875, 0.3125 , 0.2125 , 0.33125, 0.19375,\n",
       "        0.33125, 0.1875 , 0.3375 , 0.1375 , 0.34375, 0.2375 , 0.2375 ,\n",
       "        0.3    , 0.3625 , 0.25   , 0.30625, 0.25   , 0.30625, 0.21875,\n",
       "        0.3125 , 0.21875, 0.3125 , 0.2125 , 0.33125, 0.19375, 0.33125,\n",
       "        0.1875 , 0.3375 , 0.1375 , 0.34375, 0.2375 , 0.2375 , 0.3    ,\n",
       "        0.3625 , 0.25   , 0.30625, 0.25   , 0.30625, 0.21875, 0.3125 ,\n",
       "        0.21875, 0.3125 , 0.2125 , 0.33125, 0.19375, 0.33125, 0.1875 ,\n",
       "        0.3375 , 0.1375 , 0.34375, 0.2375 , 0.2375 , 0.3    , 0.3625 ,\n",
       "        0.25   , 0.30625, 0.25   , 0.30625, 0.21875, 0.3125 , 0.21875,\n",
       "        0.3125 , 0.2125 , 0.33125, 0.19375, 0.33125, 0.1875 , 0.3375 ,\n",
       "        0.1375 , 0.34375, 0.2375 , 0.2375 , 0.3    , 0.3625 , 0.25   ,\n",
       "        0.30625, 0.25   , 0.30625, 0.21875, 0.3125 , 0.21875, 0.3125 ,\n",
       "        0.2125 , 0.33125, 0.19375, 0.33125, 0.1875 , 0.3375 , 0.1375 ,\n",
       "        0.34375, 0.2375 , 0.2375 , 0.3    , 0.3625 , 0.25   , 0.30625,\n",
       "        0.25   , 0.30625, 0.21875, 0.3125 , 0.21875, 0.3125 , 0.2125 ,\n",
       "        0.33125, 0.19375, 0.33125, 0.1875 , 0.3375 , 0.1375 , 0.34375,\n",
       "        0.2375 , 0.2375 , 0.3    , 0.3625 , 0.25   , 0.30625, 0.25   ,\n",
       "        0.30625, 0.21875, 0.3125 , 0.21875, 0.3125 , 0.2125 , 0.33125,\n",
       "        0.19375, 0.33125, 0.1875 , 0.3375 , 0.1375 , 0.34375, 0.2375 ,\n",
       "        0.2375 , 0.3    , 0.3625 , 0.25   , 0.30625, 0.25   , 0.30625,\n",
       "        0.21875, 0.3125 , 0.21875, 0.3125 , 0.2125 , 0.33125, 0.19375,\n",
       "        0.33125, 0.1875 , 0.3375 , 0.1375 , 0.34375]),\n",
       " 'mean_test_score': array([0.24875, 0.24875, 0.27   , 0.3075 , 0.2425 , 0.28875, 0.23125,\n",
       "        0.29   , 0.23125, 0.2925 , 0.23   , 0.29625, 0.2    , 0.30125,\n",
       "        0.1875 , 0.30125, 0.1925 , 0.30125, 0.1525 , 0.3025 , 0.24875,\n",
       "        0.24875, 0.27   , 0.3075 , 0.2425 , 0.28875, 0.23125, 0.29   ,\n",
       "        0.23125, 0.2925 , 0.23   , 0.29625, 0.2    , 0.30125, 0.1875 ,\n",
       "        0.30125, 0.1925 , 0.30125, 0.1525 , 0.3025 , 0.24875, 0.24875,\n",
       "        0.27   , 0.3075 , 0.2425 , 0.28875, 0.23125, 0.29   , 0.23125,\n",
       "        0.2925 , 0.23   , 0.29625, 0.2    , 0.30125, 0.1875 , 0.30125,\n",
       "        0.1925 , 0.30125, 0.1525 , 0.3025 , 0.24875, 0.24875, 0.27   ,\n",
       "        0.3075 , 0.2425 , 0.28875, 0.23125, 0.29   , 0.23125, 0.2925 ,\n",
       "        0.23   , 0.29625, 0.2    , 0.30125, 0.1875 , 0.30125, 0.1925 ,\n",
       "        0.30125, 0.1525 , 0.3025 , 0.24875, 0.24875, 0.27   , 0.3075 ,\n",
       "        0.2425 , 0.28875, 0.23125, 0.29   , 0.23125, 0.2925 , 0.23   ,\n",
       "        0.29625, 0.2    , 0.30125, 0.1875 , 0.30125, 0.1925 , 0.30125,\n",
       "        0.1525 , 0.3025 , 0.24875, 0.24875, 0.27   , 0.3075 , 0.2425 ,\n",
       "        0.28875, 0.23125, 0.29   , 0.23125, 0.2925 , 0.23   , 0.29625,\n",
       "        0.2    , 0.30125, 0.1875 , 0.30125, 0.1925 , 0.30125, 0.1525 ,\n",
       "        0.3025 , 0.24875, 0.24875, 0.27   , 0.3075 , 0.2425 , 0.28875,\n",
       "        0.23125, 0.29   , 0.23125, 0.2925 , 0.23   , 0.29625, 0.2    ,\n",
       "        0.30125, 0.1875 , 0.30125, 0.1925 , 0.30125, 0.1525 , 0.3025 ,\n",
       "        0.24875, 0.24875, 0.27   , 0.3075 , 0.2425 , 0.28875, 0.23125,\n",
       "        0.29   , 0.23125, 0.2925 , 0.23   , 0.29625, 0.2    , 0.30125,\n",
       "        0.1875 , 0.30125, 0.1925 , 0.30125, 0.1525 , 0.3025 , 0.24875,\n",
       "        0.24875, 0.27   , 0.3075 , 0.2425 , 0.28875, 0.23125, 0.29   ,\n",
       "        0.23125, 0.2925 , 0.23   , 0.29625, 0.2    , 0.30125, 0.1875 ,\n",
       "        0.30125, 0.1925 , 0.30125, 0.1525 , 0.3025 ]),\n",
       " 'std_test_score': array([0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684,\n",
       "        0.02106537, 0.02106537, 0.03386554, 0.03292985, 0.03020761,\n",
       "        0.02888555, 0.01936492, 0.02755676, 0.01723006, 0.02968586,\n",
       "        0.01      , 0.03699662, 0.01976424, 0.03172144, 0.00395285,\n",
       "        0.035     , 0.01334635, 0.035     , 0.01510381, 0.03526684]),\n",
       " 'rank_test_score': array([ 91,  91,  82,   1, 109,  73, 118,  64, 118,  55, 136,  46, 145,\n",
       "         19, 163,  19, 154,  19, 172,  10,  91,  91,  82,   1, 109,  73,\n",
       "        118,  64, 118,  55, 136,  46, 145,  19, 163,  19, 154,  19, 172,\n",
       "         10,  91,  91,  82,   1, 109,  73, 118,  64, 118,  55, 136,  46,\n",
       "        145,  19, 163,  19, 154,  19, 172,  10,  91,  91,  82,   1, 109,\n",
       "         73, 118,  64, 118,  55, 136,  46, 145,  19, 163,  19, 154,  19,\n",
       "        172,  10,  91,  91,  82,   1, 109,  73, 118,  64, 118,  55, 136,\n",
       "         46, 145,  19, 163,  19, 154,  19, 172,  10,  91,  91,  82,   1,\n",
       "        109,  73, 118,  64, 118,  55, 136,  46, 145,  19, 163,  19, 154,\n",
       "         19, 172,  10,  91,  91,  82,   1, 109,  73, 118,  64, 118,  55,\n",
       "        136,  46, 145,  19, 163,  19, 154,  19, 172,  10,  91,  91,  82,\n",
       "          1, 109,  73, 118,  64, 118,  55, 136,  46, 145,  19, 163,  19,\n",
       "        154,  19, 172,  10,  91,  91,  82,   1, 109,  73, 118,  64, 118,\n",
       "         55, 136,  46, 145,  19, 163,  19, 154,  19, 172,  10], dtype=int32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN: Train and Test with Optimal Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=51, weights='distance')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.80,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "stdscale.fit(X_train)\n",
    "\n",
    "X_train = stdscale.transform(X_train)\n",
    "X_test = stdscale.transform(X_test)\n",
    "\n",
    "#optimized parameters\n",
    "classifier = KNeighborsClassifier(n_neighbors=51,\n",
    "                                  weights='distance')\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test:\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "matches = (pred==y_test).sum()\n",
    "\n",
    "accuracy = matches / pred.shape\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.28 s, sys: 34.4 ms, total: 3.31 s\n",
      "Wall time: 9.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1024)\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "# In this case, 8 max_feature values\n",
    "param_grid = {\n",
    "    \"max_features\": [1, 2, 4, 6, 8, 12, 16, 20]}\n",
    "\n",
    "# Array to store scores\n",
    "rfscores = np.zeros(3)\n",
    "best_rfmodel = []\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(3):\n",
    "\n",
    "     # Create test/train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=2,\n",
    "                                                    stratify=y_p)\n",
    "    # Create inner cv\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(RandomForestClassifier(), param_grid, cv=inner_cv, n_jobs = -1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rfscores[i] = clf.best_score_\n",
    "    best_rfmodel.append(clf.best_estimator_.fit(X_train, y_train))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79   , 0.78375, 0.775  ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(max_features=16),\n",
       " RandomForestClassifier(max_features=12),\n",
       " RandomForestClassifier(max_features=12)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.23200054, 0.2948998 , 0.38339229, 0.43104992, 0.47556448,\n",
       "        0.59285536, 0.70158343, 0.67200928]),\n",
       " 'std_fit_time': array([0.00682509, 0.01009461, 0.00689627, 0.01100309, 0.00195177,\n",
       "        0.00719719, 0.01145282, 0.05385502]),\n",
       " 'mean_score_time': array([0.01753812, 0.02128177, 0.01623001, 0.01585641, 0.01595674,\n",
       "        0.01526537, 0.01319051, 0.0094254 ]),\n",
       " 'std_score_time': array([0.00178513, 0.00033257, 0.00067606, 0.00130834, 0.000771  ,\n",
       "        0.00058734, 0.00197986, 0.00035958]),\n",
       " 'param_max_features': masked_array(data=[1, 2, 4, 6, 8, 12, 16, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_features': 1},\n",
       "  {'max_features': 2},\n",
       "  {'max_features': 4},\n",
       "  {'max_features': 6},\n",
       "  {'max_features': 8},\n",
       "  {'max_features': 12},\n",
       "  {'max_features': 16},\n",
       "  {'max_features': 20}],\n",
       " 'split0_test_score': array([0.71875, 0.7125 , 0.7375 , 0.76875, 0.7875 , 0.80625, 0.7625 ,\n",
       "        0.775  ]),\n",
       " 'split1_test_score': array([0.68125, 0.7125 , 0.775  , 0.71875, 0.7125 , 0.775  , 0.74375,\n",
       "        0.73125]),\n",
       " 'split2_test_score': array([0.71875, 0.75625, 0.7125 , 0.7625 , 0.76875, 0.78125, 0.7375 ,\n",
       "        0.75625]),\n",
       " 'split3_test_score': array([0.64375, 0.70625, 0.65625, 0.69375, 0.74375, 0.75625, 0.74375,\n",
       "        0.73125]),\n",
       " 'split4_test_score': array([0.73125, 0.75   , 0.775  , 0.79375, 0.8    , 0.75625, 0.8    ,\n",
       "        0.7875 ]),\n",
       " 'mean_test_score': array([0.69875, 0.7275 , 0.73125, 0.7475 , 0.7625 , 0.775  , 0.7575 ,\n",
       "        0.75625]),\n",
       " 'std_test_score': array([0.03221025, 0.02113942, 0.0443706 , 0.03614208, 0.03137475,\n",
       "        0.0185405 , 0.02284458, 0.02270738]),\n",
       " 'rank_test_score': array([8, 7, 6, 5, 2, 1, 3, 4], dtype=int32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Train and Test with Optimal Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.80,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "stdscale.fit(X_train)\n",
    "\n",
    "X_train = stdscale.transform(X_train)\n",
    "X_test = stdscale.transform(X_test)\n",
    "\n",
    "#optimized parameters\n",
    "classifier = RandomForestClassifier(max_features=12)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test:\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "matches = (pred==y_test).sum()\n",
    "\n",
    "accuracy = matches / pred.shape\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 18 s, total: 1min 24s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NN = MLPClassifier()\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "# In this case, there are many\n",
    "param_grid = {\n",
    "    \"solver\": ['lbfgs', 'sgd', 'adam'],\n",
    "    \"hidden_layer_sizes\": [50, 100, 150],\n",
    "    \"activation\": ['logistic','relu'],\n",
    "    \"learning_rate\": ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "\n",
    "# Array to store scores\n",
    "nnscores = np.zeros(3)\n",
    "best_nnmodel = []\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(3):\n",
    "\n",
    "     # Create test/train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=3,\n",
    "                                                    stratify=y_p)\n",
    "    # Create inner cv\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(NN, param_grid, cv=inner_cv, n_jobs = -1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    nnscores[i] = clf.best_score_\n",
    "    best_nnmodel.append(clf.best_estimator_.fit(X_train, y_train))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29375, 0.28375, 0.2975 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MLPClassifier(activation='logistic', hidden_layer_sizes=100,\n",
       "               learning_rate='invscaling', solver='lbfgs'),\n",
       " MLPClassifier(activation='logistic', hidden_layer_sizes=150,\n",
       "               learning_rate='invscaling', solver='lbfgs'),\n",
       " MLPClassifier(activation='logistic', hidden_layer_sizes=150, solver='lbfgs')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_nnmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.11279516, 1.27592349, 1.35177059, 0.92226501, 0.57143426,\n",
       "        1.13943448, 1.26693268, 1.31065617, 1.48941102, 2.88939056,\n",
       "        1.82277884, 1.87338452, 2.95988569, 0.62192869, 1.26921744,\n",
       "        2.33940139, 1.79030633, 1.96940823, 4.27898664, 2.49687099,\n",
       "        2.6843132 , 4.64824171, 1.33528886, 2.26306973, 4.80885544,\n",
       "        2.39703364, 2.17821779, 0.08800201, 0.08382673, 0.37501698,\n",
       "        0.08845439, 0.08289933, 0.30606041, 0.08739886, 0.42535553,\n",
       "        0.27597775, 0.12845111, 0.10507298, 0.46874743, 0.12198243,\n",
       "        0.09974465, 0.54157972, 0.12303338, 0.56737123, 0.29199023,\n",
       "        0.16694341, 0.13533149, 0.69034767, 0.18698325, 0.13152695,\n",
       "        0.53170547, 0.17430978, 0.57672839, 0.46955695]),\n",
       " 'std_fit_time': array([0.45040784, 0.00777996, 0.09810455, 0.21264975, 0.40743131,\n",
       "        0.4501891 , 0.2276283 , 0.04369236, 0.18927961, 0.55059499,\n",
       "        0.09540394, 0.23751915, 0.27126731, 0.17089548, 0.64409602,\n",
       "        0.48409084, 0.0126391 , 0.17217868, 1.01796105, 0.03682332,\n",
       "        0.12305523, 1.11354898, 0.45926978, 0.77021389, 0.52825725,\n",
       "        0.02300954, 0.42540143, 0.00332959, 0.00395833, 0.11885774,\n",
       "        0.00724272, 0.00650322, 0.16963681, 0.00749709, 0.007023  ,\n",
       "        0.16794043, 0.00304923, 0.00417434, 0.20521899, 0.00415178,\n",
       "        0.00315806, 0.20051651, 0.00193131, 0.01531376, 0.09101658,\n",
       "        0.01425334, 0.00356183, 0.09170134, 0.01812687, 0.00201576,\n",
       "        0.12981536, 0.00436943, 0.02123742, 0.06998151]),\n",
       " 'mean_score_time': array([0.00142798, 0.00144625, 0.00146642, 0.00138769, 0.00323658,\n",
       "        0.0014421 , 0.00146623, 0.00164218, 0.00168638, 0.00204206,\n",
       "        0.00309143, 0.00178089, 0.00207834, 0.00170293, 0.00176063,\n",
       "        0.00197024, 0.00161867, 0.00178676, 0.00267997, 0.00454602,\n",
       "        0.0022974 , 0.00316505, 0.00202785, 0.00231609, 0.00320659,\n",
       "        0.00200567, 0.0021894 , 0.00173626, 0.00227342, 0.001755  ,\n",
       "        0.00172005, 0.00154991, 0.00151753, 0.00268836, 0.00148344,\n",
       "        0.00148211, 0.00210366, 0.00175276, 0.00165219, 0.00293694,\n",
       "        0.00203948, 0.00211973, 0.00277691, 0.00272431, 0.00172372,\n",
       "        0.00310416, 0.00246162, 0.00215158, 0.00266614, 0.00237875,\n",
       "        0.00193477, 0.00420566, 0.00123706, 0.00135937]),\n",
       " 'std_score_time': array([7.24314859e-05, 4.10747539e-05, 8.40526906e-05, 6.09609033e-05,\n",
       "        3.31240138e-03, 1.00498519e-04, 9.75673847e-05, 2.33394931e-04,\n",
       "        1.46649359e-04, 3.72068307e-04, 1.03352431e-03, 8.60383383e-05,\n",
       "        3.06856971e-04, 1.20907193e-04, 1.55274800e-04, 9.43327325e-05,\n",
       "        4.21313086e-05, 4.50550307e-05, 5.94798881e-05, 3.12837590e-03,\n",
       "        3.39447174e-04, 8.03655049e-04, 1.28941881e-04, 4.77166887e-04,\n",
       "        1.53050475e-03, 1.50904730e-04, 4.77041463e-04, 1.63016921e-04,\n",
       "        1.15378292e-03, 4.29271655e-04, 1.48286129e-04, 3.55734755e-04,\n",
       "        1.87062980e-04, 2.25972274e-03, 1.10893912e-04, 1.29312716e-04,\n",
       "        4.18559134e-04, 1.83836254e-04, 2.98484064e-05, 1.36995621e-03,\n",
       "        6.87874357e-04, 7.42592966e-04, 1.51908603e-03, 1.86697661e-03,\n",
       "        1.17748600e-04, 1.38746868e-03, 8.34309392e-04, 6.47610407e-04,\n",
       "        8.65694001e-04, 7.42083324e-04, 1.01113204e-04, 3.62589079e-03,\n",
       "        2.47397419e-04, 4.56154115e-04]),\n",
       " 'param_activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 150, 150, 150, 150, 150, 150,\n",
       "                    150, 150, 150, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 150, 150, 150,\n",
       "                    150, 150, 150, 150, 150, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=['constant', 'constant', 'constant', 'invscaling',\n",
       "                    'invscaling', 'invscaling', 'adaptive', 'adaptive',\n",
       "                    'adaptive', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'adaptive',\n",
       "                    'adaptive', 'adaptive', 'constant', 'constant',\n",
       "                    'constant', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'constant',\n",
       "                    'constant', 'constant', 'invscaling', 'invscaling',\n",
       "                    'invscaling', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'invscaling',\n",
       "                    'invscaling', 'invscaling', 'adaptive', 'adaptive',\n",
       "                    'adaptive', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'adaptive',\n",
       "                    'adaptive', 'adaptive'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'logistic',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 50,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'constant',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'invscaling',\n",
       "   'solver': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'lbfgs'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'hidden_layer_sizes': 150,\n",
       "   'learning_rate': 'adaptive',\n",
       "   'solver': 'adam'}],\n",
       " 'split0_test_score': array([0.26875, 0.21875, 0.29375, 0.25625, 0.11875, 0.24375, 0.2625 ,\n",
       "        0.3    , 0.30625, 0.35   , 0.30625, 0.29375, 0.35625, 0.1    ,\n",
       "        0.28125, 0.28125, 0.275  , 0.29375, 0.28125, 0.34375, 0.325  ,\n",
       "        0.325  , 0.125  , 0.33125, 0.29375, 0.29375, 0.38125, 0.1375 ,\n",
       "        0.11875, 0.2625 , 0.09375, 0.09375, 0.24375, 0.11875, 0.13125,\n",
       "        0.20625, 0.09375, 0.09375, 0.20625, 0.1375 , 0.11875, 0.2125 ,\n",
       "        0.1    , 0.09375, 0.3    , 0.11875, 0.1    , 0.29375, 0.08125,\n",
       "        0.09375, 0.21875, 0.1375 , 0.09375, 0.25625]),\n",
       " 'split1_test_score': array([0.2875 , 0.2    , 0.35625, 0.2625 , 0.075  , 0.23125, 0.1875 ,\n",
       "        0.21875, 0.26875, 0.29375, 0.31875, 0.31875, 0.31875, 0.125  ,\n",
       "        0.26875, 0.3375 , 0.3    , 0.275  , 0.36875, 0.3125 , 0.2875 ,\n",
       "        0.3125 , 0.15   , 0.35   , 0.31875, 0.31875, 0.35   , 0.09375,\n",
       "        0.09375, 0.15625, 0.0875 , 0.06875, 0.18125, 0.11875, 0.0875 ,\n",
       "        0.21875, 0.10625, 0.11875, 0.25   , 0.1375 , 0.11875, 0.3125 ,\n",
       "        0.11875, 0.09375, 0.1375 , 0.08125, 0.075  , 0.1625 , 0.06875,\n",
       "        0.1    , 0.325  , 0.01875, 0.1    , 0.325  ]),\n",
       " 'split2_test_score': array([0.20625, 0.2375 , 0.20625, 0.20625, 0.09375, 0.23125, 0.23125,\n",
       "        0.21875, 0.21875, 0.23125, 0.2375 , 0.19375, 0.25   , 0.1    ,\n",
       "        0.2625 , 0.24375, 0.23125, 0.275  , 0.26875, 0.2375 , 0.3    ,\n",
       "        0.2875 , 0.09375, 0.24375, 0.2625 , 0.25625, 0.25625, 0.1125 ,\n",
       "        0.125  , 0.2375 , 0.125  , 0.1125 , 0.2875 , 0.20625, 0.075  ,\n",
       "        0.16875, 0.14375, 0.075  , 0.28125, 0.075  , 0.125  , 0.19375,\n",
       "        0.075  , 0.075  , 0.15   , 0.1375 , 0.075  , 0.2625 , 0.1    ,\n",
       "        0.075  , 0.2    , 0.10625, 0.075  , 0.20625]),\n",
       " 'split3_test_score': array([0.2625 , 0.2625 , 0.25   , 0.29375, 0.1375 , 0.26875, 0.25   ,\n",
       "        0.20625, 0.2375 , 0.18125, 0.25   , 0.25   , 0.23125, 0.0625 ,\n",
       "        0.24375, 0.2125 , 0.225  , 0.225  , 0.275  , 0.2    , 0.21875,\n",
       "        0.25   , 0.1625 , 0.25625, 0.25625, 0.225  , 0.225  , 0.0875 ,\n",
       "        0.11875, 0.2125 , 0.05625, 0.0875 , 0.13125, 0.06875, 0.125  ,\n",
       "        0.2125 , 0.1    , 0.1    , 0.24375, 0.08125, 0.08125, 0.225  ,\n",
       "        0.01875, 0.1125 , 0.21875, 0.125  , 0.10625, 0.21875, 0.175  ,\n",
       "        0.0875 , 0.2125 , 0.10625, 0.125  , 0.275  ]),\n",
       " 'split4_test_score': array([0.2625 , 0.21875, 0.25625, 0.25625, 0.075  , 0.2125 , 0.275  ,\n",
       "        0.1875 , 0.2    , 0.275  , 0.25   , 0.24375, 0.2625 , 0.1    ,\n",
       "        0.2625 , 0.20625, 0.25   , 0.25625, 0.29375, 0.2625 , 0.2625 ,\n",
       "        0.2625 , 0.09375, 0.21875, 0.23125, 0.2375 , 0.25625, 0.1    ,\n",
       "        0.1    , 0.20625, 0.11875, 0.10625, 0.28125, 0.1625 , 0.1    ,\n",
       "        0.2375 , 0.10625, 0.0875 , 0.18125, 0.10625, 0.0875 , 0.275  ,\n",
       "        0.05625, 0.10625, 0.19375, 0.075  , 0.075  , 0.24375, 0.11875,\n",
       "        0.0875 , 0.21875, 0.025  , 0.14375, 0.21875]),\n",
       " 'mean_test_score': array([0.2575 , 0.2275 , 0.2725 , 0.255  , 0.1    , 0.2375 , 0.24125,\n",
       "        0.22625, 0.24625, 0.26625, 0.2725 , 0.26   , 0.28375, 0.0975 ,\n",
       "        0.26375, 0.25625, 0.25625, 0.265  , 0.2975 , 0.27125, 0.27875,\n",
       "        0.2875 , 0.125  , 0.28   , 0.2725 , 0.26625, 0.29375, 0.10625,\n",
       "        0.11125, 0.215  , 0.09625, 0.09375, 0.225  , 0.135  , 0.10375,\n",
       "        0.20875, 0.11   , 0.095  , 0.2325 , 0.1075 , 0.10625, 0.24375,\n",
       "        0.07375, 0.09625, 0.2    , 0.1075 , 0.08625, 0.23625, 0.10875,\n",
       "        0.08875, 0.235  , 0.07875, 0.1075 , 0.25625]),\n",
       " 'std_test_score': array([0.02721443, 0.02113942, 0.05024938, 0.02806243, 0.02468552,\n",
       "        0.0185405 , 0.03051639, 0.03860861, 0.03762479, 0.05709094,\n",
       "        0.03321333, 0.04322904, 0.04653628, 0.02      , 0.0121192 ,\n",
       "        0.0485734 , 0.02795085, 0.02325134, 0.03657185, 0.05147815,\n",
       "        0.03614208, 0.02850439, 0.02822897, 0.05129571, 0.03051639,\n",
       "        0.03504461, 0.060596  , 0.01767767, 0.0121192 , 0.03548767,\n",
       "        0.0245586 , 0.01530931, 0.06020797, 0.04636809, 0.02150581,\n",
       "        0.02256934, 0.0175    , 0.0144698 , 0.035     , 0.02663409,\n",
       "        0.01811422, 0.04366062, 0.03477607, 0.01286954, 0.05796012,\n",
       "        0.02481179, 0.01391941, 0.04426483, 0.03720719, 0.00829156,\n",
       "        0.04551785, 0.04786047, 0.02417385, 0.04238956]),\n",
       " 'rank_test_score': array([16, 28,  9, 20, 45, 24, 23, 29, 21, 11,  7, 15,  4, 46, 14, 17, 17,\n",
       "        13,  1, 10,  6,  3, 35,  5,  7, 11,  2, 42, 36, 31, 47, 50, 30, 34,\n",
       "        44, 32, 37, 49, 27, 39, 42, 22, 54, 48, 33, 39, 52, 25, 38, 51, 26,\n",
       "        53, 39, 17], dtype=int32)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: Train and Test with Optimal Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott/.pyenv/versions/3.8.6/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100,\n",
       "              learning_rate='invscaling', solver='lbfgs')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=0.80,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "stdscale.fit(X_train)\n",
    "\n",
    "X_train = stdscale.transform(X_train)\n",
    "X_test = stdscale.transform(X_test)\n",
    "\n",
    "#optimized parameters\n",
    "classifier = MLPClassifier(activation='logistic',\n",
    "                           hidden_layer_sizes=100,\n",
    "                           learning_rate='invscaling',\n",
    "                           solver='lbfgs')\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test:\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "matches = (pred==y_test).sum()\n",
    "\n",
    "accuracy = matches / pred.shape\n",
    "accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
